{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "DL_pytorch_chapter2.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "authorship_tag": "ABX9TyMti0A3Uod3XI/3Q1Qprvnc"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "tensor 생성 예시"
   ],
   "metadata": {
    "id": "dxoeTzZrV2_O",
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bWAKKeOQMPDt",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657444372122,
     "user_tz": -540,
     "elapsed": 316,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "4046aa3f-031a-41fa-cb61-15636b742736",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.tensor([[1,2],[3,4]]))\n",
    "##print(torch.tensor([[1,2],[3,4]],device=\"cuda:0\"))  available on local gpu machine\n",
    "print(torch.tensor([[1,2],[3,4]],dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy\n",
    "temp = torch.tensor([[1,2],[3,4]])\n",
    "print(temp.numpy())"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "legZmVynV7zp",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657444426377,
     "user_tz": -540,
     "elapsed": 447,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "f57faa85-583f-41e0-e481-bba5ce4d7a69",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "v = torch.tensor([1,2,3])\n",
    "w = torch.tensor([3,4,6])\n",
    "print(w-v)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74HwLDksZJzL",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657444692253,
     "user_tz": -540,
     "elapsed": 334,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "10791686-4d95-4bf7-8772-68191b2aafde",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([2, 2, 3])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "temp = torch.tensor([[1,2],[3,4]])\n",
    "print(temp.shape)\n",
    "print(temp.view(4,1))\n",
    "print(temp.view(-1))\n",
    "print(temp.view(1,-1))\n",
    "print(temp.view(-1,1))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MUjiQ_u5aAxk",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657444802693,
     "user_tz": -540,
     "elapsed": 5,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "51935454-94a8-459e-e241-9389b94090ac",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "torch.Size([2, 2])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "tensor([1, 2, 3, 4])\n",
      "tensor([[1, 2, 3, 4]])\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n",
    "print(model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YoG7R_GvbWd8",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657445167934,
     "user_tz": -540,
     "elapsed": 3,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "73787bb2-7bea-417f-e11e-72204925ea00",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Linear(in_features=1, out_features=1, bias=True)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "class MLP(nn.Module):\n",
    "  def __init__(self,inputs):\n",
    "    super(MLP,self).__init__()\n",
    "    self.layer=nn.Linear(inputs,1)\n",
    "    self.activation=nn.Sigmoid()\n",
    "  def forward(self,X):\n",
    "    X=self.layer(X)\n",
    "    X=self.activation(X)\n",
    "    return X"
   ],
   "metadata": {
    "id": "p_tU58nzb-57",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657445359688,
     "user_tz": -540,
     "elapsed": 307,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class MLP(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MLP,self).__init__()\n",
    "    self.layer1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3,out_channels=64,kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2))\n",
    "    self.layer2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=64,out_channels=30,kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2))\n",
    "    self.layer3 = nn.Sequential(\n",
    "        nn.Linear(in_features=30*5*5,out_features=10,bias=True),\n",
    "        nn.ReLU(inplace=True))\n",
    "  def forward(self,x):\n",
    "    x=self.layer1(x)\n",
    "    x=self.layer2(x)\n",
    "    x=x.view(x.shape[0],-1)\n",
    "    x=self.layer3(x)\n",
    "    return x\n",
    "model = MLP()\n",
    "print(list(model.children()))\n",
    "print(list(model.modules()))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wu4eT7Qwctr7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657445672279,
     "user_tz": -540,
     "elapsed": 305,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "bea6a5b2-c5e7-4197-bab8-82bf8a62c15d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Sequential(\n",
      "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Sequential(\n",
      "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      ")]\n",
      "[MLP(\n",
      "  (layer1): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "  )\n",
      "), Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Conv2d(3, 64, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (1): ReLU(inplace=True)\n",
      "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "), Conv2d(64, 30, kernel_size=(5, 5), stride=(1, 1)), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Sequential(\n",
      "  (0): Linear(in_features=750, out_features=10, bias=True)\n",
      "  (1): ReLU(inplace=True)\n",
      "), Linear(in_features=750, out_features=10, bias=True), ReLU(inplace=True)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive/')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jdhApoEFm1Xu",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657454712024,
     "user_tz": -540,
     "elapsed": 15786,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "9b0791b1-a554-4633-c53c-d6d05ca97e8e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive/\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "%matplotlib inline\n",
    "#dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/dl_pytorch/chap02/data/car_evaluation.csv')\n",
    "dataset = pd.read_csv('./dl_pytorch/chap02/data/car_evaluation.csv')\n",
    "dataset.head()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "fCb6KMlRnxCB",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657454715541,
     "user_tz": -540,
     "elapsed": 1160,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "1d8db1c5-65d8-416d-b2e4-8b3dc5954ff3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "   price  maint doors persons lug_capacity safety output\n0  vhigh  vhigh     2       2        small    low  unacc\n1  vhigh  vhigh     2       2        small    med  unacc\n2  vhigh  vhigh     2       2        small   high  unacc\n3  vhigh  vhigh     2       2          med    low  unacc\n4  vhigh  vhigh     2       2          med    med  unacc",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>price</th>\n      <th>maint</th>\n      <th>doors</th>\n      <th>persons</th>\n      <th>lug_capacity</th>\n      <th>safety</th>\n      <th>output</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>vhigh</td>\n      <td>vhigh</td>\n      <td>2</td>\n      <td>2</td>\n      <td>small</td>\n      <td>low</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>vhigh</td>\n      <td>vhigh</td>\n      <td>2</td>\n      <td>2</td>\n      <td>small</td>\n      <td>med</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>vhigh</td>\n      <td>vhigh</td>\n      <td>2</td>\n      <td>2</td>\n      <td>small</td>\n      <td>high</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>vhigh</td>\n      <td>vhigh</td>\n      <td>2</td>\n      <td>2</td>\n      <td>med</td>\n      <td>low</td>\n      <td>unacc</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>vhigh</td>\n      <td>vhigh</td>\n      <td>2</td>\n      <td>2</td>\n      <td>med</td>\n      <td>med</td>\n      <td>unacc</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0]=8\n",
    "fig_size[1]=6\n",
    "plt.rcParams[\"figure.figsize\"]=fig_size\n",
    "dataset.output.value_counts().plot(kind='pie',autopct='%0.05f%%',colors=['lightblue','lightgreen','orange','pink'],explode=(0.05,0.05,0.05,0.05))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 375
    },
    "id": "pr3LefxJt7qE",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657454718137,
     "user_tz": -540,
     "elapsed": 4,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "569072ea-b7fb-423a-ce64-7650980e3e5e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "<AxesSubplot:ylabel='output'>"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 576x432 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "categorical_columns = ['price','maint','doors','persons','lug_capacity','safety']\n",
    "for category in categorical_columns:\n",
    "  dataset[category] = dataset[category].astype('category') #astype 이용해서 categorical datatype으로 변환\n",
    "price= dataset['price'].cat.codes.values\n",
    "maint= dataset['maint'].cat.codes.values\n",
    "doors= dataset['doors'].cat.codes.values\n",
    "persons= dataset['persons'].cat.codes.values\n",
    "lug_capacity= dataset['lug_capacity'].cat.codes.values\n",
    "safety= dataset['safety'].cat.codes.values\n",
    "\n",
    "categorical_data = np.stack([price,maint,doors,persons,lug_capacity,safety],1)\n",
    "categorical_data[:10]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jfhiPJrxvCJ1",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657454719729,
     "user_tz": -540,
     "elapsed": 2,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "c594e90d-ff18-4fdc-a834-f297e6f3957e",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[3, 3, 0, 0, 2, 1],\n       [3, 3, 0, 0, 2, 2],\n       [3, 3, 0, 0, 2, 0],\n       [3, 3, 0, 0, 1, 1],\n       [3, 3, 0, 0, 1, 2],\n       [3, 3, 0, 0, 1, 0],\n       [3, 3, 0, 0, 0, 1],\n       [3, 3, 0, 0, 0, 2],\n       [3, 3, 0, 0, 0, 0],\n       [3, 3, 0, 1, 2, 1]], dtype=int8)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "categorical_data = torch.tensor(categorical_data,dtype=torch.int64)\n",
    "categorical_data[:10]"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XMe72yUTvvig",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657454721957,
     "user_tz": -540,
     "elapsed": 2,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "bceacd4c-0017-4f9b-ba41-008c195d7ddc",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9856\\4246351941.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  categorical_data = torch.tensor(categorical_data,dtype=torch.int64)\n"
     ]
    },
    {
     "data": {
      "text/plain": "tensor([[3, 3, 0, 0, 2, 1],\n        [3, 3, 0, 0, 2, 2],\n        [3, 3, 0, 0, 2, 0],\n        [3, 3, 0, 0, 1, 1],\n        [3, 3, 0, 0, 1, 2],\n        [3, 3, 0, 0, 1, 0],\n        [3, 3, 0, 0, 0, 1],\n        [3, 3, 0, 0, 0, 2],\n        [3, 3, 0, 0, 0, 0],\n        [3, 3, 0, 1, 2, 1]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "outputs=pd.get_dummies(dataset.output)\n",
    "outputs=outputs.values\n",
    "outputs=torch.tensor(outputs).flatten()\n",
    "print(categorical_data.shape)\n",
    "print(outputs.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zojBSGCewtnv",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657454723339,
     "user_tz": -540,
     "elapsed": 2,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "590b6d50-e7a3-417b-dbaf-0ce9a15bb351",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1728, 6])\n",
      "torch.Size([6912])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "categorical_column_sizes =[len(dataset[column].cat.categories) for column in categorical_columns]\n",
    "categorical_embedding_sizes=[(col_size,min(50,(col_size+1)//2)) for col_size in categorical_column_sizes]\n",
    "print(categorical_embedding_sizes)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aFP7DkvSxysr",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657454724336,
     "user_tz": -540,
     "elapsed": 2,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "d3b7b82d-0824-498c-bf16-8751dae2412d",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 2), (4, 2), (4, 2), (3, 2), (3, 2), (3, 2)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "total_records = 1728\n",
    "test_records = int(total_records*.2)\n",
    "\n",
    "categorical_train_data = categorical_data[:total_records-test_records]\n",
    "categorical_test_data = categorical_data[total_records-test_records:total_records]\n",
    "train_outputs=outputs[:total_records-test_records]\n",
    "test_outputs=outputs[total_records-test_records:total_records]\n",
    "print(len(categorical_train_data))\n",
    "print(len(categorical_test_data))\n",
    "print(len(train_outputs))\n",
    "print(len(test_outputs))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KaLJj9k-yTnO",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657454725983,
     "user_tz": -540,
     "elapsed": 2,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "cf79b219-1cf6-4490-989b-c0654f5c793f",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383\n",
      "345\n",
      "1383\n",
      "345\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "네트워크 생성"
   ],
   "metadata": {
    "id": "aaYqX2n2y-tw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Model(nn.Module):\n",
    "  def __init__(self,embedding_size,output_size,layers,p=0.4):\n",
    "    super().__init__()\n",
    "    self.all_embeddings=nn.ModuleList([nn.Embedding(ni,nf) for ni,nf in embedding_size])\n",
    "    self.embedding_dropout = nn.Dropout(p)\n",
    "\n",
    "    all_layers=[]\n",
    "    num_categorical_cols = sum((nf for ni,nf in embedding_size))\n",
    "    input_size = num_categorical_cols\n",
    "\n",
    "    for i in layers:\n",
    "      all_layers.append(nn.Linear(input_size,i))\n",
    "      all_layers.append(nn.ReLU(inplace=True))\n",
    "      all_layers.append(nn.BatchNorm1d(i))\n",
    "      all_layers.append(nn.Dropout(p))\n",
    "      input_size = i\n",
    "    \n",
    "    all_layers.append(nn.Linear(layers[-1],output_size))\n",
    "    self.layers = nn.Sequential(*all_layers)\n",
    "  def forward(self,x_categorical):\n",
    "    embeddings = []\n",
    "    for i,e in enumerate(self.all_embeddings):\n",
    "      embeddings.append(e(x_categorical[:,i]))\n",
    "      x=torch.cat(embeddings,1)\n",
    "      x=self.embedding_dropout(x)\n",
    "      x=self.layers(x)\n",
    "      return x\n",
    "    "
   ],
   "metadata": {
    "id": "ZSBlIjetzAwJ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657454727547,
     "user_tz": -540,
     "elapsed": 2,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model = Model(categorical_embedding_sizes,4,[100,75,50],p=0.4)\n",
    "print(model)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8bp7ksk70U3C",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657454729090,
     "user_tz": -540,
     "elapsed": 313,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "4a8cdc4e-954e-402b-e41b-ec22b493a84a",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0): Embedding(4, 2)\n",
      "    (1): Embedding(4, 2)\n",
      "    (2): Embedding(4, 2)\n",
      "    (3): Embedding(3, 2)\n",
      "    (4): Embedding(3, 2)\n",
      "    (5): Embedding(3, 2)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=100, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=100, out_features=75, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(75, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=75, out_features=50, bias=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.4, inplace=False)\n",
      "    (12): Linear(in_features=50, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "loss_fn=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device('cuda')\n",
    "else:\n",
    "  device = torch.device('cpu')"
   ],
   "metadata": {
    "id": "4da3twSA0qEn",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1657454731264,
     "user_tz": -540,
     "elapsed": 2,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "epochs=500\n",
    "aggregated_losses=[]\n",
    "train_outputs = train_outputs.to(device=device,dtype=torch.int64)\n",
    "for i in range(epochs):\n",
    "  i+=1\n",
    "  y_pred = model(categorical_train_data)\n",
    "  single_loss=loss_fn(y_pred,train_outputs)\n",
    "  aggregated_losses.append(single_loss)\n",
    "\n",
    "  if i%25==1:\n",
    "    print(f'epoch:{i:3} loss:{single_loss.item():10.8f}')\n",
    "  \n",
    "  optimizer.zero_grad()\n",
    "  single_loss.backward()\n",
    "  optimizer.step()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "ZP538gs51O2f",
    "executionInfo": {
     "status": "error",
     "timestamp": 1657455122076,
     "user_tz": -540,
     "elapsed": 493,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "150f6737-5376-479e-b01e-f364c8927718",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 17,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1383x2 and 12x100)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m      5\u001B[0m   i\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m----> 6\u001B[0m   y_pred \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcategorical_train_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m   single_loss\u001B[38;5;241m=\u001B[39mloss_fn(y_pred,train_outputs)\n\u001B[0;32m      8\u001B[0m   aggregated_losses\u001B[38;5;241m.\u001B[39mappend(single_loss)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Input \u001B[1;32mIn [14]\u001B[0m, in \u001B[0;36mModel.forward\u001B[1;34m(self, x_categorical)\u001B[0m\n\u001B[0;32m     24\u001B[0m x\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mcat(embeddings,\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     25\u001B[0m x\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membedding_dropout(x)\n\u001B[1;32m---> 26\u001B[0m x\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\torch\\nn\\modules\\container.py:139\u001B[0m, in \u001B[0;36mSequential.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m    138\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m:\n\u001B[1;32m--> 139\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43mmodule\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28minput\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *input, **kwargs)\u001B[0m\n\u001B[0;32m   1126\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1127\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1128\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1129\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1130\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28minput\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1131\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[0;32m   1132\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\torch\\nn\\modules\\linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (1383x2 and 12x100)"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_outputs = test_outputs.to(device=device,dtype=torch.int64)\n",
    "with torch.no_grad():\n",
    "  y_val = model(categorical_test_data)\n",
    "  loss = loss_fn(y_val,test_outputs)\n",
    "print(f'Loss:{loss:.8f}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 400
    },
    "id": "UJmShrHt86vq",
    "executionInfo": {
     "status": "error",
     "timestamp": 1657453983000,
     "user_tz": -540,
     "elapsed": 309,
     "user": {
      "displayName": "이관희",
      "userId": "11190648948809132572"
     }
    },
    "outputId": "a883b96d-73e3-4d0c-83b4-d5e2c337ffc3",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 94,
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-94-86bd30b28055>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0mtest_outputs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtest_outputs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mto\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mdevice\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mint64\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mno_grad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m   \u001B[0my_val\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcategorical_test_data\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m   \u001B[0mloss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mloss_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_val\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mtest_outputs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34mf'Loss:{loss:.8f}'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1108\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1111\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1112\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-75-5ac4fcc200e2>\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, x_categorical)\u001B[0m\n\u001B[1;32m     24\u001B[0m       \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0membeddings\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     25\u001B[0m       \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0membedding_dropout\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 26\u001B[0;31m       \u001B[0mx\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     27\u001B[0m       \u001B[0;32mreturn\u001B[0m \u001B[0mx\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1108\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1111\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1112\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    139\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    140\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mmodule\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 141\u001B[0;31m             \u001B[0minput\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodule\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    142\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    143\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001B[0m in \u001B[0;36m_call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1108\u001B[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001B[1;32m   1109\u001B[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001B[0;32m-> 1110\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mforward_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1111\u001B[0m         \u001B[0;31m# Do not call functions when jit is used\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1112\u001B[0m         \u001B[0mfull_backward_hooks\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnon_full_backward_hooks\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001B[0m in \u001B[0;36mforward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    101\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    102\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mforward\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minput\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mTensor\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 103\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mF\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlinear\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mweight\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbias\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    105\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mextra_repr\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mstr\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: mat1 and mat2 shapes cannot be multiplied (345x2 and 12x200)"
     ]
    }
   ]
  }
 ]
}