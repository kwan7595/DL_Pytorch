{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14308\\2600277882.py:9: FutureWarning: The squeeze argument has been deprecated and will be removed in a future version. Append .squeeze(\"columns\") to the call to squeeze.\n",
      "\n",
      "\n",
      "  series = read_csv('./dl_pytorch/chap07/data/SBUX.csv',header=0,parse_dates=[0],index_col=0,squeeze=True,\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14308\\2600277882.py:9: FutureWarning: \n",
      "        Use pd.to_datetime instead.\n",
      "\n",
      "  series = read_csv('./dl_pytorch/chap07/data/SBUX.csv',header=0,parse_dates=[0],index_col=0,squeeze=True,\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:1086\u001B[0m, in \u001B[0;36m_make_date_converter.<locals>.converter\u001B[1;34m(*date_cols)\u001B[0m\n\u001B[0;32m   1084\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1085\u001B[0m     result \u001B[38;5;241m=\u001B[39m tools\u001B[38;5;241m.\u001B[39mto_datetime(\n\u001B[1;32m-> 1086\u001B[0m         \u001B[43mdate_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdate_cols\u001B[49m\u001B[43m)\u001B[49m, errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m, cache\u001B[38;5;241m=\u001B[39mcache_dates\n\u001B[0;32m   1087\u001B[0m     )\n\u001B[0;32m   1088\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(result, datetime\u001B[38;5;241m.\u001B[39mdatetime):\n",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36mparser\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparser\u001B[39m(x):\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mto_datetime\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m199\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mY-\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1076\u001B[0m, in \u001B[0;36mto_datetime\u001B[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001B[0m\n\u001B[0;32m   1075\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1076\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_listlike\u001B[49m\u001B[43m(\u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1077\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:402\u001B[0m, in \u001B[0;36m_convert_listlike_datetimes\u001B[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001B[0m\n\u001B[0;32m    401\u001B[0m utc \u001B[38;5;241m=\u001B[39m tz \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutc\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 402\u001B[0m result, tz_parsed \u001B[38;5;241m=\u001B[39m \u001B[43mobjects_to_datetime64ns\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    403\u001B[0m \u001B[43m    \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdayfirst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdayfirst\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43myearfirst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43myearfirst\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    406\u001B[0m \u001B[43m    \u001B[49m\u001B[43mutc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mutc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    407\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequire_iso8601\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequire_iso8601\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    409\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_object\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    412\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tz_parsed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    413\u001B[0m     \u001B[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001B[39;00m\n\u001B[0;32m    414\u001B[0m     \u001B[38;5;66;03m# is in UTC\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2216\u001B[0m, in \u001B[0;36mobjects_to_datetime64ns\u001B[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001B[0m\n\u001B[0;32m   2186\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2187\u001B[0m \u001B[38;5;124;03mConvert data to array of timestamps.\u001B[39;00m\n\u001B[0;32m   2188\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2214\u001B[0m \u001B[38;5;124;03mValueError : if data cannot be converted to datetimes\u001B[39;00m\n\u001B[0;32m   2215\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m-> 2216\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m errors \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoerce\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   2218\u001B[0m \u001B[38;5;66;03m# if str-dtype, convert\u001B[39;00m\n",
      "\u001B[1;31mAssertionError\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:1094\u001B[0m, in \u001B[0;36m_make_date_converter.<locals>.converter\u001B[1;34m(*date_cols)\u001B[0m\n\u001B[0;32m   1092\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1093\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tools\u001B[38;5;241m.\u001B[39mto_datetime(\n\u001B[1;32m-> 1094\u001B[0m         \u001B[43mparsing\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtry_parse_dates\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1095\u001B[0m \u001B[43m            \u001B[49m\u001B[43mparsing\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconcat_date_cols\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdate_cols\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1096\u001B[0m \u001B[43m            \u001B[49m\u001B[43mparser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdate_parser\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1097\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdayfirst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdayfirst\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1098\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m   1099\u001B[0m         errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1100\u001B[0m     )\n\u001B[0;32m   1101\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\_libs\\tslibs\\parsing.pyx:656\u001B[0m, in \u001B[0;36mpandas._libs.tslibs.parsing.try_parse_dates\u001B[1;34m()\u001B[0m\n",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36mparser\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparser\u001B[39m(x):\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mto_datetime\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m199\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mY-\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1078\u001B[0m, in \u001B[0;36mto_datetime\u001B[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001B[0m\n\u001B[0;32m   1077\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1078\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_listlike\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43marg\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1080\u001B[0m \u001B[38;5;66;03m#  error: Incompatible return value type (got \"Union[Timestamp, NaTType,\u001B[39;00m\n\u001B[0;32m   1081\u001B[0m \u001B[38;5;66;03m# Series, Index]\", expected \"Union[DatetimeIndex, Series, float, str,\u001B[39;00m\n\u001B[0;32m   1082\u001B[0m \u001B[38;5;66;03m# NaTType, None]\")\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:402\u001B[0m, in \u001B[0;36m_convert_listlike_datetimes\u001B[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001B[0m\n\u001B[0;32m    401\u001B[0m utc \u001B[38;5;241m=\u001B[39m tz \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutc\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 402\u001B[0m result, tz_parsed \u001B[38;5;241m=\u001B[39m \u001B[43mobjects_to_datetime64ns\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    403\u001B[0m \u001B[43m    \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdayfirst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdayfirst\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43myearfirst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43myearfirst\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    406\u001B[0m \u001B[43m    \u001B[49m\u001B[43mutc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mutc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    407\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequire_iso8601\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequire_iso8601\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    409\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_object\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    412\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tz_parsed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    413\u001B[0m     \u001B[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001B[39;00m\n\u001B[0;32m    414\u001B[0m     \u001B[38;5;66;03m# is in UTC\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2216\u001B[0m, in \u001B[0;36mobjects_to_datetime64ns\u001B[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001B[0m\n\u001B[0;32m   2186\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2187\u001B[0m \u001B[38;5;124;03mConvert data to array of timestamps.\u001B[39;00m\n\u001B[0;32m   2188\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2214\u001B[0m \u001B[38;5;124;03mValueError : if data cannot be converted to datetimes\u001B[39;00m\n\u001B[0;32m   2215\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m-> 2216\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m errors \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoerce\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   2218\u001B[0m \u001B[38;5;66;03m# if str-dtype, convert\u001B[39;00m\n",
      "\u001B[1;31mAssertionError\u001B[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36m<cell line: 9>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparser\u001B[39m(x):\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m to_datetime(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m199\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m+\u001B[39mx,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mY-\u001B[39m\u001B[38;5;124m%\u001B[39m\u001B[38;5;124mm\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 9\u001B[0m series \u001B[38;5;241m=\u001B[39m \u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./dl_pytorch/chap07/data/SBUX.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mheader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43mparse_dates\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43mindex_col\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43msqueeze\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mdate_parser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparser\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     11\u001B[0m model\u001B[38;5;241m=\u001B[39mARIMA(series,order\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m5\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m0\u001B[39m))\n\u001B[0;32m     12\u001B[0m model_fit \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfit(disp\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001B[0m, in \u001B[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m num_allow_args:\n\u001B[0;32m    306\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[0;32m    307\u001B[0m         msg\u001B[38;5;241m.\u001B[39mformat(arguments\u001B[38;5;241m=\u001B[39marguments),\n\u001B[0;32m    308\u001B[0m         \u001B[38;5;167;01mFutureWarning\u001B[39;00m,\n\u001B[0;32m    309\u001B[0m         stacklevel\u001B[38;5;241m=\u001B[39mstacklevel,\n\u001B[0;32m    310\u001B[0m     )\n\u001B[1;32m--> 311\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001B[0m, in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    665\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[0;32m    666\u001B[0m     dialect,\n\u001B[0;32m    667\u001B[0m     delimiter,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    676\u001B[0m     defaults\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdelimiter\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m\"\u001B[39m},\n\u001B[0;32m    677\u001B[0m )\n\u001B[0;32m    678\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[1;32m--> 680\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:581\u001B[0m, in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    578\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n\u001B[0;32m    580\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m parser:\n\u001B[1;32m--> 581\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1255\u001B[0m, in \u001B[0;36mTextFileReader.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m   1253\u001B[0m nrows \u001B[38;5;241m=\u001B[39m validate_integer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnrows\u001B[39m\u001B[38;5;124m\"\u001B[39m, nrows)\n\u001B[0;32m   1254\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1255\u001B[0m     index, columns, col_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnrows\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1256\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m   1257\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:311\u001B[0m, in \u001B[0;36mCParserWrapper.read\u001B[1;34m(self, nrows)\u001B[0m\n\u001B[0;32m    308\u001B[0m     data \u001B[38;5;241m=\u001B[39m {k: v \u001B[38;5;28;01mfor\u001B[39;00m k, (i, v) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(names, data_tups)}\n\u001B[0;32m    310\u001B[0m     names, date_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_date_conversions(names, data)\n\u001B[1;32m--> 311\u001B[0m     index, names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdate_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43malldata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnames\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    313\u001B[0m \u001B[38;5;66;03m# maybe create a mi on the columns\u001B[39;00m\n\u001B[0;32m    314\u001B[0m conv_names \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_make_multi_index_columns(names, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcol_names)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:390\u001B[0m, in \u001B[0;36mParserBase._make_index\u001B[1;34m(self, data, alldata, columns, indexnamerow)\u001B[0m\n\u001B[0;32m    388\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_complex_date_col:\n\u001B[0;32m    389\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_simple_index(alldata, columns)\n\u001B[1;32m--> 390\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_agg_index\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    391\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_has_complex_date_col:\n\u001B[0;32m    392\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_name_processed:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:482\u001B[0m, in \u001B[0;36mParserBase._agg_index\u001B[1;34m(self, index, try_parse_dates)\u001B[0m\n\u001B[0;32m    479\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, arr \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(index):\n\u001B[0;32m    481\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m try_parse_dates \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_should_parse_dates(i):\n\u001B[1;32m--> 482\u001B[0m         arr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_date_conv\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    484\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mna_filter:\n\u001B[0;32m    485\u001B[0m         col_na_values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mna_values\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:1102\u001B[0m, in \u001B[0;36m_make_date_converter.<locals>.converter\u001B[1;34m(*date_cols)\u001B[0m\n\u001B[0;32m   1093\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tools\u001B[38;5;241m.\u001B[39mto_datetime(\n\u001B[0;32m   1094\u001B[0m         parsing\u001B[38;5;241m.\u001B[39mtry_parse_dates(\n\u001B[0;32m   1095\u001B[0m             parsing\u001B[38;5;241m.\u001B[39mconcat_date_cols(date_cols),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1099\u001B[0m         errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   1100\u001B[0m     )\n\u001B[0;32m   1101\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m-> 1102\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgeneric_parser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdate_parser\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mdate_cols\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\io\\date_converters.py:101\u001B[0m, in \u001B[0;36mgeneric_parser\u001B[1;34m(parse_func, *cols)\u001B[0m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(N):\n\u001B[0;32m    100\u001B[0m     args \u001B[38;5;241m=\u001B[39m [c[i] \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m cols]\n\u001B[1;32m--> 101\u001B[0m     results[i] \u001B[38;5;241m=\u001B[39m \u001B[43mparse_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    103\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m results\n",
      "Input \u001B[1;32mIn [11]\u001B[0m, in \u001B[0;36mparser\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparser\u001B[39m(x):\n\u001B[1;32m----> 8\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mto_datetime\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m199\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mY-\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mm\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1078\u001B[0m, in \u001B[0;36mto_datetime\u001B[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001B[0m\n\u001B[0;32m   1076\u001B[0m         result \u001B[38;5;241m=\u001B[39m convert_listlike(arg, \u001B[38;5;28mformat\u001B[39m)\n\u001B[0;32m   1077\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1078\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mconvert_listlike\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43marray\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43marg\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m   1080\u001B[0m \u001B[38;5;66;03m#  error: Incompatible return value type (got \"Union[Timestamp, NaTType,\u001B[39;00m\n\u001B[0;32m   1081\u001B[0m \u001B[38;5;66;03m# Series, Index]\", expected \"Union[DatetimeIndex, Series, float, str,\u001B[39;00m\n\u001B[0;32m   1082\u001B[0m \u001B[38;5;66;03m# NaTType, None]\")\u001B[39;00m\n\u001B[0;32m   1083\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py:402\u001B[0m, in \u001B[0;36m_convert_listlike_datetimes\u001B[1;34m(arg, format, name, tz, unit, errors, infer_datetime_format, dayfirst, yearfirst, exact)\u001B[0m\n\u001B[0;32m    400\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mformat\u001B[39m \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m infer_datetime_format\n\u001B[0;32m    401\u001B[0m utc \u001B[38;5;241m=\u001B[39m tz \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutc\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 402\u001B[0m result, tz_parsed \u001B[38;5;241m=\u001B[39m \u001B[43mobjects_to_datetime64ns\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    403\u001B[0m \u001B[43m    \u001B[49m\u001B[43marg\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    404\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdayfirst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdayfirst\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    405\u001B[0m \u001B[43m    \u001B[49m\u001B[43myearfirst\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43myearfirst\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    406\u001B[0m \u001B[43m    \u001B[49m\u001B[43mutc\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mutc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    407\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    408\u001B[0m \u001B[43m    \u001B[49m\u001B[43mrequire_iso8601\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequire_iso8601\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    409\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_object\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    410\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    412\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tz_parsed \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    413\u001B[0m     \u001B[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001B[39;00m\n\u001B[0;32m    414\u001B[0m     \u001B[38;5;66;03m# is in UTC\u001B[39;00m\n\u001B[0;32m    415\u001B[0m     dta \u001B[38;5;241m=\u001B[39m DatetimeArray(result, dtype\u001B[38;5;241m=\u001B[39mtz_to_dtype(tz_parsed))\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\torch_book\\lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2216\u001B[0m, in \u001B[0;36mobjects_to_datetime64ns\u001B[1;34m(data, dayfirst, yearfirst, utc, errors, require_iso8601, allow_object, allow_mixed)\u001B[0m\n\u001B[0;32m   2176\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mobjects_to_datetime64ns\u001B[39m(\n\u001B[0;32m   2177\u001B[0m     data: np\u001B[38;5;241m.\u001B[39mndarray,\n\u001B[0;32m   2178\u001B[0m     dayfirst,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2184\u001B[0m     allow_mixed: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[0;32m   2185\u001B[0m ):\n\u001B[0;32m   2186\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2187\u001B[0m \u001B[38;5;124;03m    Convert data to array of timestamps.\u001B[39;00m\n\u001B[0;32m   2188\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   2214\u001B[0m \u001B[38;5;124;03m    ValueError : if data cannot be converted to datetimes\u001B[39;00m\n\u001B[0;32m   2215\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m-> 2216\u001B[0m     \u001B[38;5;28;01massert\u001B[39;00m errors \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcoerce\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m   2218\u001B[0m     \u001B[38;5;66;03m# if str-dtype, convert\u001B[39;00m\n\u001B[0;32m   2219\u001B[0m     data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(data, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mobject_)\n",
      "\u001B[1;31mAssertionError\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from pandas import to_datetime\n",
    "from pandas import DataFrame\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "from matplotlib import pyplot\n",
    "\n",
    "def parser(x):\n",
    "    return to_datetime('199'+x,'%Y-%m')\n",
    "series = read_csv('./dl_pytorch/chap07/data/SBUX.csv',header=0,parse_dates=[0],index_col=0,squeeze=True,\n",
    "                  date_parser=parser)\n",
    "model=ARIMA(series,order=(5,1,0))\n",
    "model_fit = model.fit(disp=0)\n",
    "print(model_fit.summary())\n",
    "residuals = DataFrame(model_fit.resid)\n",
    "residuals.plot()\n",
    "pyplot.show()\n",
    "residuals.plot(kind='kde')\n",
    "pyplot.show()\n",
    "print(residuals.describe)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "7.4.1 RNN 셀 구현"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchtext\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "TEXT = torchtext.legacy.data.Field(lower=True,fix_length=200,batch_first=False)\n",
    "LABEL = torchtext.legacy.data.Field(sequential=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "from torchtext.legacy import datasets\n",
    "train_data,test_data =datasets.IMDB.splits(TEXT,LABEL)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': ['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy.', 'it', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life,', 'such', 'as', '\"teachers\".', 'my', '35', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me', 'to', 'believe', 'that', 'bromwell', \"high's\", 'satire', 'is', 'much', 'closer', 'to', 'reality', 'than', 'is', '\"teachers\".', 'the', 'scramble', 'to', 'survive', 'financially,', 'the', 'insightful', 'students', 'who', 'can', 'see', 'right', 'through', 'their', 'pathetic', \"teachers'\", 'pomp,', 'the', 'pettiness', 'of', 'the', 'whole', 'situation,', 'all', 'remind', 'me', 'of', 'the', 'schools', 'i', 'knew', 'and', 'their', 'students.', 'when', 'i', 'saw', 'the', 'episode', 'in', 'which', 'a', 'student', 'repeatedly', 'tried', 'to', 'burn', 'down', 'the', 'school,', 'i', 'immediately', 'recalled', '.........', 'at', '..........', 'high.', 'a', 'classic', 'line:', 'inspector:', \"i'm\", 'here', 'to', 'sack', 'one', 'of', 'your', 'teachers.', 'student:', 'welcome', 'to', 'bromwell', 'high.', 'i', 'expect', 'that', 'many', 'adults', 'of', 'my', 'age', 'think', 'that', 'bromwell', 'high', 'is', 'far', 'fetched.', 'what', 'a', 'pity', 'that', 'it', \"isn't!\"], 'label': 'pos'}\n"
     ]
    }
   ],
   "source": [
    "print(vars(train_data.examples[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import string\n",
    "for example in train_data.examples:\n",
    "    text = [x.lower() for x in vars(example)['text']] # 소문자\n",
    "    text = [x.replace(\"<br\",\"\") for x in text] # <br -> 공백\n",
    "    text = [''.join(c for c in s if c not in string.punctuation) for s in text] # 구두점 제거\n",
    "    text = [s for s in text if s] #공백 제거\n",
    "    vars(example)['text']=text"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "import random\n",
    "train_data, valid_data = train_data.split(random_state=random.seed(0),split_ratio=0.8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples : 20000\n",
      "Number of validation examples : 5000\n",
      "Number of testing examples:25000\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of training examples : {len(train_data)}')\n",
    "print(f'Number of validation examples : {len(valid_data)}')\n",
    "print(f'Number of testing examples:{len(test_data)}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique tokens in TEXT vocabulary:10002\n",
      "Unique tokens in LABEL vocabulary:3\n"
     ]
    }
   ],
   "source": [
    "TEXT.build_vocab(train_data,max_size=10000,min_freq=10,vectors=None)\n",
    "LABEL.build_vocab(train_data)\n",
    "\n",
    "print(f'Unique tokens in TEXT vocabulary:{len(TEXT.vocab)}')\n",
    "print(f'Unique tokens in LABEL vocabulary:{len(LABEL.vocab)}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x000002A4CDBDFDF0>>, {'<unk>': 0, 'pos': 1, 'neg': 2})\n"
     ]
    }
   ],
   "source": [
    "print(LABEL.vocab.stoi)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "BATCH_SIZE=32\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "embedding_dim = 100\n",
    "hidden_size = 300\n",
    "\n",
    "train_iterator, valid_iterator,test_iterator = torchtext.legacy.data.BucketIterator.splits(\n",
    "    (train_data,valid_data,test_data),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    device=device\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class RNNCell_Encoder(nn.Module):\n",
    "    def __init__(self,input_dim,hidden_size):\n",
    "        super(RNNCell_Encoder,self).__init__()\n",
    "        self.rnn = nn.RNNCell(input_dim,hidden_size)\n",
    "\n",
    "    def forward(self,inputs):\n",
    "        bz = inputs.shape[1]\n",
    "        ht = torch.zeros((bz,hidden_size)).to(device)\n",
    "        for word in inputs:\n",
    "            ht = self.rnn(word,ht) # 재귀 처리\n",
    "        return ht\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net,self).__init__()\n",
    "        self.em = nn.Embedding(len(TEXT.vocab.stoi),embedding_dim)\n",
    "        self.rnn = RNNCell_Encoder(embedding_dim,hidden_size)\n",
    "        self.fc1 = nn.Linear(hidden_size,256)\n",
    "        self.fc2 = nn.Linear(256,3)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.em(x)\n",
    "        x = self.rnn(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "model = Net()\n",
    "model.to(device)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.0001)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "def training(epoch,model,trainloader,validloader):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss =0\n",
    "\n",
    "    model.train()\n",
    "    for b in trainloader:\n",
    "        x,y = b.text,b.label\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred,y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            y_pred = torch.argmax(y_pred,dim=1)\n",
    "            correct +=(y_pred==y).sum().item()\n",
    "            total +=y.size(0)\n",
    "            running_loss +=loss.item()\n",
    "\n",
    "    epoch_loss = running_loss / len(trainloader.dataset)\n",
    "    epoch_acc = correct/total\n",
    "\n",
    "    valid_correct = 0\n",
    "    valid_total = 0\n",
    "    valid_running_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for b in validloader:\n",
    "            x,y = b.text,b.label\n",
    "            x,y = x.to(device),y.to(device)\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred,y)\n",
    "            y_pred = torch.argmax(y_pred,dim=1)\n",
    "            valid_correct +=(y_pred==y).sum().item()\n",
    "            valid_total +=y.size(0)\n",
    "            valid_running_loss +=loss.item()\n",
    "    epoch_valid_loss = valid_running_loss / len(validloader.dataset)\n",
    "    epoch_valid_acc = valid_correct/valid_total\n",
    "\n",
    "    print('epoch: ',epoch,\n",
    "          'loss: ',round(epoch_loss,3),\n",
    "          'accuracy',round(epoch_acc,3),\n",
    "          'valid_loss: ',round(epoch_valid_loss,3),\n",
    "          'valid_acc : ',round(epoch_valid_acc,3))\n",
    "    return epoch_loss,epoch_acc,epoch_valid_loss,epoch_valid_acc"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 loss:  0.022 accuracy 0.497 valid_loss:  0.022 valid_acc :  0.491\n",
      "epoch:  1 loss:  0.022 accuracy 0.503 valid_loss:  0.022 valid_acc :  0.515\n",
      "epoch:  2 loss:  0.022 accuracy 0.513 valid_loss:  0.022 valid_acc :  0.517\n",
      "epoch:  3 loss:  0.022 accuracy 0.529 valid_loss:  0.022 valid_acc :  0.517\n",
      "epoch:  4 loss:  0.021 accuracy 0.532 valid_loss:  0.022 valid_acc :  0.5\n",
      "2714.220121383667\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "train_loss = []\n",
    "train_acc = []\n",
    "valid_loss = []\n",
    "valid_acc = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss,epoch_acc,epoch_valid_loss,epoch_valid_acc = training(epoch,model,train_iterator,valid_iterator)\n",
    "    train_loss.append(epoch_loss)\n",
    "    train_acc.append(epoch_acc)\n",
    "    valid_loss.append(epoch_valid_loss)\n",
    "    valid_acc.append(epoch_valid_acc)\n",
    "end = time.time()\n",
    "print(end-start)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}